{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91efe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0df36",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(__file__).parent / \"mock_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28001652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_json(filename: str) -> dict:\n",
    "    with open(DATA_DIR / filename) as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa512e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_agent_investigate(state: SharedState) -> SharedState:\n",
    "\n",
    "    print(\"\\n [METRICS AGENT] Analyzing infrastructure metrics…\")\n",
    "\n",
    "    svc = state.raw_metrics.get(\"services\", {}).get(\"payment-service\", {})\n",
    "    pod_data = svc.get(\"pods\", {}).get(\"pay-pod-9b1e\", {})\n",
    "    mem = pod_data.get(\"memory\", {})\n",
    "    latency = svc.get(\"latency\", {})\n",
    "    error_rate = svc.get(\"error_rate\", {})\n",
    "    db = svc.get(\"database\", {})\n",
    "\n",
    "    # ── Finding: Memory Leak Pattern ──\n",
    "    leak = mem.get(\"leak_analysis\", {})\n",
    "    if leak.get(\"leak_detected\"):\n",
    "        mem_ts = mem.get(\"timeseries\", [])\n",
    "        state.add_finding(Finding(\n",
    "            agent=AgentRole.METRICS_AGENT,\n",
    "            title=\"Confirmed memory leak — OOM in ~14 minutes per restart\",\n",
    "            description=(\n",
    "                f\"Memory grows at {leak['leak_rate_mb_per_min']} MiB/min. \"\n",
    "                f\"GC overhead at {leak['gc_overhead_pct']}% (stop-the-world pauses). \"\n",
    "                f\"Pod restarts every ~{leak['estimated_oom_minutes']:.0f} minutes. \"\n",
    "                f\"Suspected source: {leak['suspected_source']}. \"\n",
    "                f\"Memory trajectory: {mem_ts[0]['value']}→{mem_ts[4]['value']} MiB in first 4 minutes.\"\n",
    "            ),\n",
    "            severity=Severity.P1_CRITICAL,\n",
    "            evidence={\n",
    "                \"leak_rate_mb_per_min\": leak[\"leak_rate_mb_per_min\"],\n",
    "                \"gc_overhead_pct\": leak[\"gc_overhead_pct\"],\n",
    "                \"oom_cycle_minutes\": leak[\"estimated_oom_minutes\"],\n",
    "                \"memory_timeseries_sample\": mem_ts[:6],\n",
    "            },\n",
    "            related_services=[\"payment-service\"],\n",
    "            confidence=0.96,\n",
    "            evidence = {\n",
    "                \"leak_rate_mb_per_min\"\n",
    "            }\n",
    "        ))\n",
    "\n",
    "    # ── Finding: Latency Degradation ──\n",
    "    if latency.get(\"timeseries\"):\n",
    "        ts = latency[\"timeseries\"]\n",
    "        p99_start = ts[0][\"p99\"]\n",
    "        p99_peak = max(t[\"p99\"] for t in ts)\n",
    "        state.add_finding(Finding(\n",
    "            agent=AgentRole.METRICS_AGENT,\n",
    "            title=f\"P99 latency spike: {p99_start}ms → {p99_peak}ms ({p99_peak/p99_start:.0f}x increase)\",\n",
    "            description=(\n",
    "                f\"P99 latency degraded from {p99_start}ms to {p99_peak}ms over the incident window. \"\n",
    "                f\"P50 also impacted: {ts[0]['p50']}ms → {max(t['p50'] for t in ts)}ms. \"\n",
    "                \"Latency shows sawtooth pattern correlated with pod restart cycles.\"\n",
    "            ),\n",
    "            severity=Severity.P1_CRITICAL,\n",
    "            evidence={\n",
    "                \"p99_start\": p99_start,\n",
    "                \"p99_peak\": p99_peak,\n",
    "                \"degradation_factor\": round(p99_peak / p99_start, 1),\n",
    "                \"latency_timeseries\": ts,\n",
    "            },\n",
    "            related_services=[\"payment-service\"],\n",
    "            confidence=0.98,\n",
    "        ))\n",
    "\n",
    "    # ── Finding: Error Rate Surge ──\n",
    "    if error_rate.get(\"timeseries\"):\n",
    "        er_ts = error_rate[\"timeseries\"]\n",
    "        peak_err = max(t[\"value\"] for t in er_ts)\n",
    "        state.add_finding(Finding(\n",
    "            agent=AgentRole.METRICS_AGENT,\n",
    "            title=f\"Error rate surged to {peak_err}%\",\n",
    "            description=(\n",
    "                f\"Error rate escalated from {er_ts[0]['value']}% to {peak_err}% \"\n",
    "                f\"across the incident window. Currently at {er_ts[-1]['value']}%. \"\n",
    "                \"Correlated with memory exhaustion and pod failures.\"\n",
    "            ),\n",
    "            severity=Severity.P1_CRITICAL,\n",
    "            evidence={\"error_rate_timeseries\": er_ts, \"peak_error_pct\": peak_err},\n",
    "            related_services=[\"payment-service\"],\n",
    "            confidence=0.97,\n",
    "        ))\n",
    "\n",
    "    # ── Finding: DB Connection Pool Saturation ──\n",
    "    if db.get(\"connection_pool\"):\n",
    "        pool = db[\"connection_pool\"]\n",
    "        state.add_finding(Finding(\n",
    "            agent=AgentRole.METRICS_AGENT,\n",
    "            title=\"Database connection pool at 100% with 1847 pending requests\",\n",
    "            description=(\n",
    "                f\"All {pool['max_size']} connections active, 0 idle. \"\n",
    "                f\"{pool['pending']} requests queued with avg checkout time of {pool['avg_checkout_time_ms']/1000:.1f}s. \"\n",
    "                \"Slow queries (avg 38s) are holding connections, starving other requests.\"\n",
    "            ),\n",
    "            severity=Severity.P1_CRITICAL,\n",
    "            evidence={\n",
    "                \"pool\": pool,\n",
    "                \"slow_queries\": db.get(\"slow_queries\", []),\n",
    "                \"replication_lag_ms\": db.get(\"replication_lag_ms\"),\n",
    "            },\n",
    "            related_services=[\"payment-service\"],\n",
    "            confidence=0.95,\n",
    "        ))\n",
    "\n",
    "    # ── Finding: Pod Health Degradation ──\n",
    "    pods = svc.get(\"pods\", {})\n",
    "    unhealthy = [name for name, info in pods.items()\n",
    "                 if isinstance(info, dict) and info.get(\"status\") in (\"CrashLoopBackOff\", \"OOMKilled\")]\n",
    "    if unhealthy:\n",
    "        gateway = state.raw_metrics.get(\"services\", {}).get(\"api-gateway\", {})\n",
    "        upstream = gateway.get(\"upstream_health\", {}).get(\"payment-service\", {})\n",
    "        state.add_finding(Finding(\n",
    "            agent=AgentRole.METRICS_AGENT,\n",
    "            title=f\"{len(unhealthy)} pods in critical state — only 33% capacity\",\n",
    "            description=(\n",
    "                f\"Pods in failure state: {unhealthy}. \"\n",
    "                f\"Healthy capacity at {upstream.get('healthy_pct', 'N/A')}%. \"\n",
    "                f\"Circuit breaker state: {upstream.get('circuit_state', 'N/A')}. \"\n",
    "                \"Remaining pods overloaded at >88% CPU.\"\n",
    "            ),\n",
    "            severity=Severity.P1_CRITICAL,\n",
    "            evidence={\n",
    "                \"unhealthy_pods\": unhealthy,\n",
    "                \"healthy_capacity_pct\": upstream.get(\"healthy_pct\"),\n",
    "                \"circuit_state\": upstream.get(\"circuit_state\"),\n",
    "            },\n",
    "            related_services=[\"payment-service\"],\n",
    "            confidence=0.99,\n",
    "        ))\n",
    "\n",
    "\n",
    "    met_findings = state.get_findings_by_agent(AgentRole.METRICS_AGENT)\n",
    "    print(f\"Produce {len(met_findings)} findings\")\n",
    "    return state\n",
    "\n",
    "    CommunicationBus.dispatch(\n",
    "        state, AgentRole.METRICS_AGENT, AgentRole.COMMANDER,\n",
    "        MessageType.STATUS_UPDATE,\n",
    "        {\"status\": \"complete\", \"findings_count\": len(state.get_findings_by_agent(AgentRole.METRICS_AGENT))},\n",
    "    )\n",
    "\n",
    "    met_findings = state.get_findings_by_agent(AgentRole.METRICS_AGENT)\n",
    "    print(f\"   Produced {len(met_findings)} findings\")\n",
    "    return state"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bayers_hackathon (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
